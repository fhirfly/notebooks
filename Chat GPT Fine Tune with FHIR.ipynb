{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning ChatGPT for FHIR Bundle Interpretation\n",
    "## Notebook Summary:\n",
    "This notebook serves as a guide to fine-tune the ChatGPT model to specialize in parsing and interpreting FHIR Bundles. The notebook walks you through the initial setup steps, including installing the OpenAI package and importing required libraries. It then guides you through the process of uploading your fine-tuning data and initiating the fine-tuning job. Lastly, it likely contains steps for monitoring and evaluating the fine-tuned model.\n",
    "\n",
    "## Fine-tuned Effect:\n",
    "The fine-tuned model is expected to be proficient in understanding and generating text based on FHIR Bundles, which are a standard for healthcare data interchange. This specialized version of ChatGPT could be invaluable in healthcare applications that require natural language interfaces to interact with complex healthcare data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install OpenAI Python Package and Import it\n",
    "In this cell, we install the OpenAI Python package, which provides the interface to interact with the OpenAI API for fine-tuning GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and set the Open AI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import os\n",
    "#Set the API key\n",
    "\n",
    "openai.api_key = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Fine-tuning File\n",
    "In this step, we upload the data file `fhirbundle_training_gpt3.5.jsonl`, which is in the data folder this repository (for reference) for the fine-tuning purpose. This file likely contains FHIR Bundles as inputs and expected Chat GPT outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = openai.File.create(\n",
    "  file=open(\"data/fhirbundle_training_gpt3.5.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testfile)\n",
    "file_id = testfile['id']\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize API and Start Fine-tuning\n",
    "First, we set the OpenAI API key. Then we initiate the fine-tuning job using the file ID obtained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a fine-tuning job\n",
    "\n",
    "fine_tuning_job = openai.FineTuningJob.create( training_file=file_id, model=\"gpt-3.5-turbo\" ) \n",
    "print(\"Fine-tuning job ID:\", fine_tuning_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive the Fine Tuning Job Status from Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_status = openai.FineTuningJob.retrieve(fine_tuning_job.id) \n",
    "print(\"Job Status:\", job_status.status)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Fine-tuning Job Status\n",
    "This cell retrieves the status of the fine-tuning job using its ID. The status will help us understand whether the fine-tuning has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if job_status.status == \"succeeded\": \n",
    "    fine_tuned_model = job_status.fine_tuned_model \n",
    "    #Run the Completion API\n",
    "    #response = openai.Completion.create( model=\"ft:gpt-3.5-turbo-0613:fly-health::7qmxnF69\", prompt=\"[resourceType] Bundle [entry][0][resource][resourceType] Patient [entry][0][resource][id] 123 [entry][0][resource][name][0][family] Smith [entry][0][resource][name][0][given][0] John [entry][0][resource][gender] male [entry][0][resource][birthDate] 1980-01-01 [entry][1][resource][resourceType] Condition [entry][1][resource][subject][reference] Patient/123 [entry][1][resource][code][coding][0][system] http://snomed.info/sct [entry][1][resource][code][coding][0][code] 44054006 [entry][1][resource][code][coding][0][display] Diabetes mellitus type 2\" ) \n",
    "    #print(\"Response:\", response.choices[0].text.strip())\n",
    "    modelid = fine_tuned_model.split(\":\")[1]\n",
    "    #Run the ChatCompletion API\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=modelid,\n",
    "        messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Given a FHIR Bundle Resource consisting of entries for all the clinical FHIR resources for a single patient, provide a comprehensive medical analysis of the patient.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"[resourceType] Bundle [entry][0][resource][resourceType] Patient [entry][0][resource][id] 123 [entry][0][resource][name][0][family] Bryan [entry][0][resource][name][0][given][0] John [entry][0][resource][gender] male [entry][0][resource][birthDate] 1980-07-01 [entry][1][resource][resourceType] Condition [entry][1][resource][subject][reference] Patient/123 [entry][1][resource][code][coding][0][system] http://snomed.info/sct [entry][1][resource][code][coding][0][code] 44054006 [entry][1][resource][code][coding][0][display] Diabetes mellitus type 2\"}\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the fine-tuning job has succeeded, this cell tests the fine-tuned model with a sample FHIR Bundle and prints out the response. It uses both the Completion API and the ChatCompletion API to demonstrate different modes of interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tine Job Utilitiy Functions\n",
    "Retrieve Job, List Jobs, Cancel Job, Delete Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(\"<YOUR JOB ID HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "openai.FineTuningJob.list_events(id=\"<YOUR MODEL ID HERE>\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel a job\n",
    "openai.FineTuningJob.cancel(\"<YOUR JOB ID HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "import openai\n",
    "openai.Model.delete(\"<YOUR MODEL ID HERE>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
