{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning ChatGPT for FHIR Bundle Interpretation\n",
    "## Notebook Summary:\n",
    "This notebook serves as a guide to fine-tune the ChatGPT model to specialize in parsing and interpreting FHIR Bundles. The notebook walks you through the initial setup steps, including installing the OpenAI package and importing required libraries. It then guides you through the process of uploading your fine-tuning data and initiating the fine-tuning job. Lastly, it likely contains steps for monitoring and evaluating the fine-tuned model.\n",
    "\n",
    "## Fine-tuned Effect:\n",
    "The fine-tuned model is expected to be proficient in understanding and generating text based on FHIR Bundles, which are a standard for healthcare data interchange. This specialized version of ChatGPT could be invaluable in healthcare applications that require natural language interfaces to interact with complex healthcare data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install OpenAI Python Package and Import it\n",
    "In this cell, we install the OpenAI Python package, which provides the interface to interact with the OpenAI API for fine-tuning GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and set the Open AI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import os\n",
    "#Set the API key\n",
    "\n",
    "openai.api_key = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Fine-tuning File\n",
    "In this step, we upload the data file `fhirbundle_training_gpt3.5.jsonl`, which is in the data folder this repository (for reference) for the fine-tuning purpose. This file likely contains FHIR Bundles as inputs and expected Chat GPT outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testfile \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mFile\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      2\u001b[0m   file\u001b[39m=\u001b[39;49m\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mdata/fhirbundle_training_gpt3.5.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      3\u001b[0m   purpose\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfine-tune\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_resources/file.py:84\u001b[0m, in \u001b[0;36mFile.create\u001b[0;34m(cls, file, purpose, model, api_key, api_base, api_type, api_version, organization, user_provided_filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     user_provided_filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ):\n\u001b[1;32m     73\u001b[0m     requestor, url, files \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__prepare_file_create(\n\u001b[1;32m     74\u001b[0m         file,\n\u001b[1;32m     75\u001b[0m         purpose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m         user_provided_filename,\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, files\u001b[39m=\u001b[39;49mfiles)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m     86\u001b[0m         response, api_key, api_version, organization\n\u001b[1;32m     87\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "testfile = openai.File.create(\n",
    "  file=open(\"data/fhirbundle_training_gpt3.5.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(testfile)\n\u001b[1;32m      2\u001b[0m file_id \u001b[39m=\u001b[39m testfile[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(file_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testfile' is not defined"
     ]
    }
   ],
   "source": [
    "print(testfile)\n",
    "file_id = testfile['id']\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize API and Start Fine-tuning\n",
    "First, we set the OpenAI API key. Then we initiate the fine-tuning job using the file ID obtained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a fine-tuning job\n",
    "\n",
    "fine_tuning_job = openai.FineTuningJob.create( training_file=file_id, model=\"gpt-3.5-turbo\" ) \n",
    "print(\"Fine-tuning job ID:\", fine_tuning_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive the Fine Tuning Job Status from Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_status = openai.FineTuningJob.retrieve(fine_tuning_job.id) \n",
    "print(\"Job Status:\", job_status.status)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Fine-tuning Job Status\n",
    "This cell retrieves the status of the fine-tuning job using its ID. The status will help us understand whether the fine-tuning has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if job_status.status == \"succeeded\": \n",
    "    fine_tuned_model = job_status.fine_tuned_model \n",
    "    #Run the Completion API\n",
    "    #response = openai.Completion.create( model=\"ft:gpt-3.5-turbo-0613:fly-health::7qmxnF69\", prompt=\"[resourceType] Bundle [entry][0][resource][resourceType] Patient [entry][0][resource][id] 123 [entry][0][resource][name][0][family] Smith [entry][0][resource][name][0][given][0] John [entry][0][resource][gender] male [entry][0][resource][birthDate] 1980-01-01 [entry][1][resource][resourceType] Condition [entry][1][resource][subject][reference] Patient/123 [entry][1][resource][code][coding][0][system] http://snomed.info/sct [entry][1][resource][code][coding][0][code] 44054006 [entry][1][resource][code][coding][0][display] Diabetes mellitus type 2\" ) \n",
    "    #print(\"Response:\", response.choices[0].text.strip())\n",
    "    modelid = fine_tuned_model.split(\":\")[1]\n",
    "    #Run the ChatCompletion API\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=modelid,\n",
    "        messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Given a FHIR Bundle Resource consisting of entries for all the clinical FHIR resources for a single patient, provide a comprehensive medical analysis of the patient.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"[resourceType] Bundle [entry][0][resource][resourceType] Patient [entry][0][resource][id] 123 [entry][0][resource][name][0][family] Bryan [entry][0][resource][name][0][given][0] John [entry][0][resource][gender] male [entry][0][resource][birthDate] 1980-07-01 [entry][1][resource][resourceType] Condition [entry][1][resource][subject][reference] Patient/123 [entry][1][resource][code][coding][0][system] http://snomed.info/sct [entry][1][resource][code][coding][0][code] 44054006 [entry][1][resource][code][coding][0][display] Diabetes mellitus type 2\"}\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the fine-tuning job has succeeded, this cell tests the fine-tuned model with a sample FHIR Bundle and prints out the response. It uses both the Completion API and the ChatCompletion API to demonstrate different modes of interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tine Job Utilitiy Functions\n",
    "Retrieve Job, List Jobs, Cancel Job, Delete Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(\"<YOUR JOB ID HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "openai.FineTuningJob.list_events(id=\"<YOUR MODEL ID HERE>\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel a job\n",
    "openai.FineTuningJob.cancel(\"<YOUR JOB ID HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "import openai\n",
    "openai.Model.delete(\"<YOUR MODEL ID HERE>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
