{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyPubMedGPT - Create Evidence Based Medicine with Pub Med using GPT and PICO Prompts\n",
    "\n",
    "We start with a clinical question.  We aren't too concerned with the format of the  question, because we will convert it to PICO later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clincal_question = \"What is the best treatment for a patient with a fractured tibia?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries\n",
    "We need to install all of the Python Libraries that this Notebook needs to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, install all of the requirements\n",
    "!pip install requests\n",
    "!pip install biopython\n",
    "!pip install openai\n",
    "!pip install transformers\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI API Key.  You must get a key from [https://platform.openai.com/] and set it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure your email so that the NCBI service knows who you are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"\"  # Always tell NCBI who you are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a chat function for ChatGPT completion, specfiy the 3.5 turbo mdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{message}\"},\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite the Clinical Question in PICO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pico_res = chat('rewrite the following clinical question according to the PICO model using (P), (I) , (C), (O) notation to the right of the clause:' + simple_clincal_question )\n",
    "print(pico_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the PICO question into its componements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to capture PICO components\n",
    "pico_string = pico_res\n",
    "\n",
    "# Refined regular expression to capture PICO components\n",
    "pattern = r\"In (?P<Patient>.*?) \\(P\\), (?P<Intervention>.*?) \\(I\\) (?P<Comparison>.*?) \\(C\\) (?P<Outcome>.*?) \\(O\\)\\?\"\n",
    "\n",
    "match = re.match(pattern, pico_string)\n",
    "\n",
    "if match:\n",
    "    pico_variables = match.groupdict()\n",
    "else:\n",
    "    pico_variables = \"No match found!\"\n",
    "\n",
    "pico_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the Entrez Mesh Database for the meshed terms on our PICO Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "query_terms = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idList = []\n",
    "handle = Entrez.esearch(db=\"mesh\", term=pico_variables['Patient'])\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "mesh_terms = []\n",
    "for translation in record['TranslationSet']:\n",
    "    terms = translation['To'].split(' OR ')\n",
    "    for term in terms:\n",
    "        if '[MeSH Terms]' in term:\n",
    "            mesh_terms.append(term.replace('[MeSH Terms]', '').replace('\"', '').strip())\n",
    "query_terms = [f\"{term}\" for term in mesh_terms]\n",
    "query = \" AND \".join(query_terms)\n",
    "p_query = query\n",
    "print(p_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.esearch(db=\"mesh\", term=pico_variables['Intervention'])\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "# Extract MeSH terms from the result\n",
    "mesh_terms = []\n",
    "for translation in record['TranslationSet']:\n",
    "    terms = translation['To'].split(' OR ')\n",
    "    for term in terms:\n",
    "        if '[MeSH Terms]' in term:\n",
    "            mesh_terms.append(term.replace('[MeSH Terms]', '').replace('\"', '').strip())\n",
    "\n",
    "query_terms = [f\"{term}\" for term in mesh_terms]\n",
    "query = \" OR \".join(query_terms)\n",
    "i_query = query\n",
    "print(i_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.esearch(db=\"mesh\", term=pico_variables['Comparison'])\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "mesh_terms = []\n",
    "for translation in record['TranslationSet']:\n",
    "    terms = translation['To'].split(' OR ')\n",
    "    for term in terms:\n",
    "        if '[MeSH Terms]' in term:\n",
    "            mesh_terms.append(term.replace('[MeSH Terms]', '').replace('\"', '').strip())\n",
    "query_terms = [f\"{term}\" for term in mesh_terms]\n",
    "query = \" OR \".join(query_terms)\n",
    "c_query = query\n",
    "print(c_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "handle = Entrez.esearch(db=\"mesh\", term=pico_variables['Outcome'])\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "mesh_terms = []\n",
    "for translation in record['TranslationSet']:\n",
    "    terms = translation['To'].split(' OR ')\n",
    "    for term in terms:\n",
    "        if '[MeSH Terms]' in term:\n",
    "            mesh_terms.append(term.replace('[MeSH Terms]', '').replace('\"', '').strip())\n",
    "query_terms = [f\"{term}\" for term in mesh_terms]\n",
    "query = \" OR \".join(query_terms)\n",
    "o_query = query\n",
    "print(o_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Final Query using the Mesh Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query = f\"({p_query}) AND ({i_query}) AND ({c_query}) AND ({o_query})\"\n",
    "print(final_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Pub Med using the Mesh Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.esearch(db=\"pubmed\", term=final_query)\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "idlist = record['IdList']\n",
    "print(idlist)\n",
    "print(record['Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the Document Title and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Medline\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\",retmode=\"text\")\n",
    "records = Medline.parse(handle)\n",
    "records = list(records)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "for record in records:\n",
    "    title = record.get(\"TI\", \"?\")\n",
    "    author = record.get(\"AU\", \"?\")\n",
    "    journal = record.get(\"TA\", \"?\")\n",
    "    date_of_publication = record.get(\"DP\", \"?\")\n",
    "    abstract = record.get(\"AB\", \"?\")\n",
    "    keywords = record.get(\"OT\", \"?\")\n",
    "    mesh_terms =record.get(\"MH\", \"?\")\n",
    "    articles.append((title, abstract, journal, author, date_of_publication, keywords, mesh_terms))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print a couple of the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles.__len__())\n",
    "#print(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Vector Database with the Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_text(text):\n",
    "    if not text:\n",
    "        return None  # or return a zero vector or another placeholder\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs['pooler_output'].numpy()\n",
    "\n",
    "    \n",
    "vectors = [embed_text(article[1]) for article in articles if article[1]]\n",
    "vectors = [v for v in vectors if v is not None]\n",
    "print(f\"Number of vectors: {len(vectors)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert vectors list to a 2D numpy array\n",
    "vectors_matrix = np.vstack(vectors)\n",
    "\n",
    "# Build the index\n",
    "index = faiss.IndexFlatL2(vectors_matrix.shape[1])\n",
    "index.add(vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Vector of the PICO Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = pico_res\n",
    "query_vector = embed_text(query_text)\n",
    "print(query_vector.shape)\n",
    "print(pico_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search the Vectorized Abstracts with the PICO Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of nearest neighbors you want to retrieve\n",
    "if len(vectors) >= 5: k = 5\n",
    "else: k = len(vectors)\n",
    "\n",
    "# Search the index for the k-nearest vectors\n",
    "D, I = index.search(query_vector, k)\n",
    "\n",
    "# D contains the distances, and I contains the indices of the nearest vectors\n",
    "nearest_articles = [articles[i] for i in I[0]]  # I[0] because I is a 2D array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the Vector Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, print the nearest articles:\n",
    "s =\"\"\n",
    "for idx, article in enumerate(nearest_articles):\n",
    "    title, abstract, journal, author, date_of_publication, keywords, mesh_terms = article\n",
    "    s = s + \"Title: \" + title + \"\\n\"\n",
    "    s = s + \"Abstract: \" + abstract + \"\\n\"\n",
    "    s = s + \"Journal: \" + journal + \"\\n\"\n",
    "    s = s + \"Author: \" + author + \"\\n\"\n",
    "    s = s + \"Date of publication: \" + date_of_publication + \"\\n\"\n",
    "    s = s + \"Keywords: \" + keywords + \"\\n\"\n",
    "    s = s + \"Mesh terms: \" + mesh_terms + \"\\n\"\n",
    "print(s)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce an Evidenced Based Medicine Report Using the Research Articles from Pub Med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_res = chat(\"Act as an evidenced-based clinical researcher. Using only the following PubMed Abstracts to guide your content (\" + s + \"), create an evidence based medicine report that answers the following question: \" + pico_res)\n",
    "print(pico_res)\n",
    "print(research_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce an Evidenced Based Medicine Report Using the ChatGPT Model with Low Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_res = chat(\"Act as an evidence-based clinical researcher. Create an evidence based medicine report that answers the following question: \" + pico_res + \"  Provide references to support your content.\")\n",
    "print(research_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
